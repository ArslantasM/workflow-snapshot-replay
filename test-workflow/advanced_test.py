#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GeliÅŸmiÅŸ Python Test DosyasÄ±
KarmaÅŸÄ±k Python Ã¶zelliklerini test etmek iÃ§in tasarlanmÄ±ÅŸ kapsamlÄ± bir sistem

Bu dosya ÅŸunlarÄ± iÃ§erir:
- Ã‡oklu kalÄ±tÄ±m ve mixin'ler
- Async/await programlama
- Decorator'lar ve metaclass'lar
- Context manager'lar
- Generator'lar ve iterator'lar
- Type hints ve dataclass'lar
- Exception handling
- Threading ve multiprocessing
- Design patterns
"""

import asyncio
import threading
import multiprocessing
import time
import functools
import contextlib
import itertools
import json
import pickle
import sqlite3
import logging
import typing
from typing import Dict, List, Optional, Union, Callable, Any, Generic, TypeVar
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
from enum import Enum, auto
from collections import defaultdict, deque, namedtuple
from datetime import datetime, timedelta
from pathlib import Path
import weakref
import gc

# Logging yapÄ±landÄ±rmasÄ±
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('advanced_test.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Type variables
T = TypeVar('T')
K = TypeVar('K')
V = TypeVar('V')

# Enums
class ProcessStatus(Enum):
    """Ä°ÅŸlem durumlarÄ±"""
    PENDING = auto()
    RUNNING = auto()
    COMPLETED = auto()
    FAILED = auto()
    CANCELLED = auto()

class Priority(Enum):
    """Ã–ncelik seviyeleri"""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

# Dataclasses
@dataclass(frozen=True)
class TaskResult:
    """GÃ¶rev sonucu veri yapÄ±sÄ±"""
    task_id: str
    status: ProcessStatus
    result: Optional[Any] = None
    error: Optional[str] = None
    execution_time: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class Configuration:
    """Sistem yapÄ±landÄ±rmasÄ±"""
    max_workers: int = 4
    timeout: float = 30.0
    retry_count: int = 3
    debug_mode: bool = False
    cache_size: int = 1000
    batch_size: int = 100
    
    def __post_init__(self):
        if self.max_workers < 1:
            raise ValueError("max_workers en az 1 olmalÄ±")
        if self.timeout <= 0:
            raise ValueError("timeout pozitif olmalÄ±")

# Metaclass
class SingletonMeta(type):
    """Singleton pattern iÃ§in metaclass"""
    _instances: Dict[type, Any] = {}
    _lock = threading.Lock()
    
    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            with cls._lock:
                if cls not in cls._instances:
                    instance = super().__call__(*args, **kwargs)
                    cls._instances[cls] = instance
        return cls._instances[cls]

# Decorators
def measure_time(func: Callable) -> Callable:
    """Fonksiyon Ã§alÄ±ÅŸma sÃ¼resini Ã¶lÃ§er"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time
            logger.info(f"{func.__name__} Ã§alÄ±ÅŸtÄ± - SÃ¼re: {execution_time:.4f}s")
            return result
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"{func.__name__} hata - SÃ¼re: {execution_time:.4f}s - Hata: {e}")
            raise
    return wrapper

def retry(max_attempts: int = 3, delay: float = 1.0):
    """Fonksiyonu belirtilen sayÄ±da yeniden dener"""
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_attempts - 1:
                        logger.warning(f"{func.__name__} deneme {attempt + 1} baÅŸarÄ±sÄ±z: {e}")
                        time.sleep(delay)
                    else:
                        logger.error(f"{func.__name__} tÃ¼m denemeler baÅŸarÄ±sÄ±z")
            raise last_exception
        return wrapper
    return decorator

def cache_result(max_size: int = 128):
    """Fonksiyon sonuÃ§larÄ±nÄ± Ã¶nbelleÄŸe alÄ±r"""
    def decorator(func: Callable) -> Callable:
        cache: Dict[str, Any] = {}
        cache_order = deque()
        
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # Cache key oluÅŸtur
            key = str(args) + str(sorted(kwargs.items()))
            
            if key in cache:
                logger.debug(f"{func.__name__} cache hit: {key[:50]}...")
                return cache[key]
            
            # Fonksiyonu Ã§alÄ±ÅŸtÄ±r
            result = func(*args, **kwargs)
            
            # Cache'e ekle
            if len(cache) >= max_size:
                oldest_key = cache_order.popleft()
                del cache[oldest_key]
            
            cache[key] = result
            cache_order.append(key)
            logger.debug(f"{func.__name__} cache miss: {key[:50]}...")
            
            return result
        
        wrapper.cache = cache
        wrapper.cache_clear = lambda: (cache.clear(), cache_order.clear())
        return wrapper
    return decorator

# Abstract Base Classes
class DataProcessor(ABC):
    """Veri iÅŸleyici abstract sÄ±nÄ±fÄ±"""
    
    @abstractmethod
    async def process(self, data: Any) -> Any:
        """Veriyi iÅŸle"""
        pass
    
    @abstractmethod
    def validate(self, data: Any) -> bool:
        """Veriyi doÄŸrula"""
        pass
    
    @property
    @abstractmethod
    def processor_type(self) -> str:
        """Ä°ÅŸleyici tipi"""
        pass

class StorageBackend(ABC):
    """Depolama backend'i abstract sÄ±nÄ±fÄ±"""
    
    @abstractmethod
    async def save(self, key: str, data: Any) -> bool:
        pass
    
    @abstractmethod
    async def load(self, key: str) -> Optional[Any]:
        pass
    
    @abstractmethod
    async def delete(self, key: str) -> bool:
        pass

# Mixins
class LoggingMixin:
    """Loglama yetenekleri ekleyen mixin"""
    
    def log_info(self, message: str):
        logger.info(f"[{self.__class__.__name__}] {message}")
    
    def log_error(self, message: str, exception: Optional[Exception] = None):
        if exception:
            logger.error(f"[{self.__class__.__name__}] {message}: {exception}")
        else:
            logger.error(f"[{self.__class__.__name__}] {message}")
    
    def log_debug(self, message: str):
        logger.debug(f"[{self.__class__.__name__}] {message}")

class CacheableMixin:
    """Ã–nbellek yetenekleri ekleyen mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._cache: Dict[str, Any] = {}
        self._cache_timestamps: Dict[str, datetime] = {}
        self._cache_ttl = timedelta(minutes=5)
    
    def get_cached(self, key: str) -> Optional[Any]:
        """Ã–nbellekten veri al"""
        if key in self._cache:
            timestamp = self._cache_timestamps.get(key)
            if timestamp and datetime.now() - timestamp < self._cache_ttl:
                return self._cache[key]
            else:
                # SÃ¼resi dolmuÅŸ, temizle
                self._cache.pop(key, None)
                self._cache_timestamps.pop(key, None)
        return None
    
    def set_cached(self, key: str, value: Any):
        """Ã–nbelleÄŸe veri kaydet"""
        self._cache[key] = value
        self._cache_timestamps[key] = datetime.now()
    
    def clear_cache(self):
        """Ã–nbelleÄŸi temizle"""
        self._cache.clear()
        self._cache_timestamps.clear()

# Generic Classes
class Repository(Generic[T]):
    """Generic repository pattern"""
    
    def __init__(self, item_type: typing.Type[T]):
        self._item_type = item_type
        self._items: Dict[str, T] = {}
        self._lock = threading.RLock()
    
    def add(self, key: str, item: T) -> None:
        """Ã–ÄŸe ekle"""
        if not isinstance(item, self._item_type):
            raise TypeError(f"Ã–ÄŸe {self._item_type} tipinde olmalÄ±")
        
        with self._lock:
            self._items[key] = item
    
    def get(self, key: str) -> Optional[T]:
        """Ã–ÄŸe al"""
        with self._lock:
            return self._items.get(key)
    
    def remove(self, key: str) -> bool:
        """Ã–ÄŸe sil"""
        with self._lock:
            return self._items.pop(key, None) is not None
    
    def list_all(self) -> List[T]:
        """TÃ¼m Ã¶ÄŸeleri listele"""
        with self._lock:
            return list(self._items.values())
    
    def count(self) -> int:
        """Ã–ÄŸe sayÄ±sÄ±"""
        with self._lock:
            return len(self._items)

# Context Managers
@contextlib.contextmanager
def database_transaction(db_path: str):
    """VeritabanÄ± transaction context manager'Ä±"""
    conn = sqlite3.connect(db_path)
    try:
        conn.execute("BEGIN TRANSACTION")
        yield conn
        conn.execute("COMMIT")
        logger.info("VeritabanÄ± transaction baÅŸarÄ±lÄ±")
    except Exception as e:
        conn.execute("ROLLBACK")
        logger.error(f"VeritabanÄ± transaction baÅŸarÄ±sÄ±z: {e}")
        raise
    finally:
        conn.close()

class ResourceManager:
    """Kaynak yÃ¶netimi context manager'Ä±"""
    
    def __init__(self, resource_name: str):
        self.resource_name = resource_name
        self.resource = None
        self.acquired_at = None
    
    def __enter__(self):
        self.acquired_at = datetime.now()
        logger.info(f"Kaynak alÄ±ndÄ±: {self.resource_name}")
        # SimÃ¼le edilmiÅŸ kaynak
        self.resource = {"name": self.resource_name, "data": "test_data"}
        return self.resource
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.acquired_at:
            duration = datetime.now() - self.acquired_at
            logger.info(f"Kaynak serbest bÄ±rakÄ±ldÄ±: {self.resource_name} (SÃ¼re: {duration})")
        
        if exc_type:
            logger.error(f"Kaynak kullanÄ±mÄ±nda hata: {exc_val}")
        
        self.resource = None
        return False  # Exception'larÄ± yeniden fÄ±rlat

# Concrete Implementations
class JSONProcessor(DataProcessor, LoggingMixin, CacheableMixin):
    """JSON veri iÅŸleyicisi"""
    
    def __init__(self):
        super().__init__()
        self.log_info("JSON processor baÅŸlatÄ±ldÄ±")
    
    async def process(self, data: Any) -> Dict[str, Any]:
        """JSON verisini iÅŸle"""
        cache_key = f"json_process_{hash(str(data))}"
        cached_result = self.get_cached(cache_key)
        
        if cached_result:
            self.log_debug("Cache'den JSON verisi alÄ±ndÄ±")
            return cached_result
        
        await asyncio.sleep(0.1)  # SimÃ¼le edilmiÅŸ iÅŸlem sÃ¼resi
        
        if isinstance(data, str):
            try:
                result = json.loads(data)
            except json.JSONDecodeError as e:
                self.log_error("JSON parse hatasÄ±", e)
                raise
        elif isinstance(data, dict):
            result = data.copy()
        else:
            result = {"processed_data": str(data)}
        
        # Metadata ekle
        result["_metadata"] = {
            "processed_at": datetime.now().isoformat(),
            "processor": self.processor_type
        }
        
        self.set_cached(cache_key, result)
        self.log_info(f"JSON verisi iÅŸlendi: {len(str(result))} karakter")
        
        return result
    
    def validate(self, data: Any) -> bool:
        """JSON verisini doÄŸrula"""
        try:
            if isinstance(data, str):
                json.loads(data)
            return True
        except (json.JSONDecodeError, TypeError):
            return False
    
    @property
    def processor_type(self) -> str:
        return "json_processor"

class MemoryStorage(StorageBackend, LoggingMixin):
    """Bellek tabanlÄ± depolama"""
    
    def __init__(self):
        super().__init__()
        self._storage: Dict[str, Any] = {}
        self._access_times: Dict[str, datetime] = {}
        self._lock = asyncio.Lock()
    
    async def save(self, key: str, data: Any) -> bool:
        """Veriyi kaydet"""
        async with self._lock:
            try:
                self._storage[key] = pickle.dumps(data)
                self._access_times[key] = datetime.now()
                self.log_info(f"Veri kaydedildi: {key}")
                return True
            except Exception as e:
                self.log_error(f"Veri kaydetme hatasÄ±: {key}", e)
                return False
    
    async def load(self, key: str) -> Optional[Any]:
        """Veriyi yÃ¼kle"""
        async with self._lock:
            try:
                if key in self._storage:
                    self._access_times[key] = datetime.now()
                    data = pickle.loads(self._storage[key])
                    self.log_debug(f"Veri yÃ¼klendi: {key}")
                    return data
                return None
            except Exception as e:
                self.log_error(f"Veri yÃ¼kleme hatasÄ±: {key}", e)
                return None
    
    async def delete(self, key: str) -> bool:
        """Veriyi sil"""
        async with self._lock:
            try:
                if key in self._storage:
                    del self._storage[key]
                    self._access_times.pop(key, None)
                    self.log_info(f"Veri silindi: {key}")
                    return True
                return False
            except Exception as e:
                self.log_error(f"Veri silme hatasÄ±: {key}", e)
                return False
    
    def get_stats(self) -> Dict[str, Any]:
        """Depolama istatistikleri"""
        return {
            "total_items": len(self._storage),
            "total_size": sum(len(data) for data in self._storage.values()),
            "last_access_times": dict(self._access_times)
        }

# Task Management System
class TaskManager(metaclass=SingletonMeta):
    """GÃ¶rev yÃ¶netim sistemi (Singleton)"""
    
    def __init__(self, config: Optional[Configuration] = None):
        if hasattr(self, '_initialized'):
            return
        
        self._initialized = True
        self.config = config or Configuration()
        self._tasks: Dict[str, TaskResult] = {}
        self._task_queue = asyncio.Queue()
        self._workers: List[asyncio.Task] = []
        self._running = False
        self._stats = defaultdict(int)
        
        logger.info(f"TaskManager baÅŸlatÄ±ldÄ± - Workers: {self.config.max_workers}")
    
    async def start(self):
        """GÃ¶rev yÃ¶neticisini baÅŸlat"""
        if self._running:
            return
        
        self._running = True
        
        # Worker'larÄ± baÅŸlat
        for i in range(self.config.max_workers):
            worker = asyncio.create_task(self._worker(f"worker_{i}"))
            self._workers.append(worker)
        
        logger.info(f"{len(self._workers)} worker baÅŸlatÄ±ldÄ±")
    
    async def stop(self):
        """GÃ¶rev yÃ¶neticisini durdur"""
        self._running = False
        
        # TÃ¼m worker'larÄ± durdur
        for worker in self._workers:
            worker.cancel()
        
        if self._workers:
            await asyncio.gather(*self._workers, return_exceptions=True)
        
        self._workers.clear()
        logger.info("TaskManager durduruldu")
    
    async def _worker(self, worker_name: str):
        """Worker coroutine"""
        logger.info(f"Worker baÅŸlatÄ±ldÄ±: {worker_name}")
        
        while self._running:
            try:
                # Queue'dan gÃ¶rev al
                task_func, task_id, args, kwargs = await asyncio.wait_for(
                    self._task_queue.get(), timeout=1.0
                )
                
                logger.debug(f"{worker_name} gÃ¶revi alÄ±ndÄ±: {task_id}")
                
                # GÃ¶revi Ã§alÄ±ÅŸtÄ±r
                start_time = time.time()
                try:
                    if asyncio.iscoroutinefunction(task_func):
                        result = await task_func(*args, **kwargs)
                    else:
                        result = task_func(*args, **kwargs)
                    
                    execution_time = time.time() - start_time
                    
                    # Sonucu kaydet
                    self._tasks[task_id] = TaskResult(
                        task_id=task_id,
                        status=ProcessStatus.COMPLETED,
                        result=result,
                        execution_time=execution_time
                    )
                    
                    self._stats['completed'] += 1
                    logger.info(f"GÃ¶rev tamamlandÄ±: {task_id} ({execution_time:.4f}s)")
                
                except Exception as e:
                    execution_time = time.time() - start_time
                    
                    self._tasks[task_id] = TaskResult(
                        task_id=task_id,
                        status=ProcessStatus.FAILED,
                        error=str(e),
                        execution_time=execution_time
                    )
                    
                    self._stats['failed'] += 1
                    logger.error(f"GÃ¶rev baÅŸarÄ±sÄ±z: {task_id} - {e}")
                
                finally:
                    self._task_queue.task_done()
            
            except asyncio.TimeoutError:
                continue
            except asyncio.CancelledError:
                logger.info(f"Worker iptal edildi: {worker_name}")
                break
            except Exception as e:
                logger.error(f"Worker hatasÄ± {worker_name}: {e}")
    
    async def submit_task(self, task_func: Callable, *args, **kwargs) -> str:
        """GÃ¶rev gÃ¶nder"""
        task_id = f"task_{int(time.time() * 1000000)}"
        
        # GÃ¶rev durumunu kaydet
        self._tasks[task_id] = TaskResult(
            task_id=task_id,
            status=ProcessStatus.PENDING
        )
        
        # Queue'ya ekle
        await self._task_queue.put((task_func, task_id, args, kwargs))
        self._stats['submitted'] += 1
        
        logger.debug(f"GÃ¶rev gÃ¶nderildi: {task_id}")
        return task_id
    
    def get_task_result(self, task_id: str) -> Optional[TaskResult]:
        """GÃ¶rev sonucunu al"""
        return self._tasks.get(task_id)
    
    def get_stats(self) -> Dict[str, Any]:
        """Ä°statistikleri al"""
        return {
            "total_tasks": len(self._tasks),
            "queue_size": self._task_queue.qsize(),
            "workers": len(self._workers),
            "running": self._running,
            **dict(self._stats)
        }

# Generator Functions
def fibonacci_generator(n: int):
    """Fibonacci sayÄ± dizisi generator'Ä±"""
    a, b = 0, 1
    count = 0
    while count < n:
        yield a
        a, b = b, a + b
        count += 1

def prime_generator(limit: int):
    """Asal sayÄ± generator'Ä±"""
    def is_prime(num):
        if num < 2:
            return False
        for i in range(2, int(num ** 0.5) + 1):
            if num % i == 0:
                return False
        return True
    
    for num in range(2, limit + 1):
        if is_prime(num):
            yield num

def batch_generator(iterable, batch_size: int):
    """Batch generator - bÃ¼yÃ¼k veri setlerini parÃ§alara bÃ¶ler"""
    iterator = iter(iterable)
    while True:
        batch = list(itertools.islice(iterator, batch_size))
        if not batch:
            break
        yield batch

# Async Functions
@measure_time
@retry(max_attempts=3)
async def complex_async_operation(data: Dict[str, Any]) -> Dict[str, Any]:
    """KarmaÅŸÄ±k async iÅŸlem"""
    logger.info(f"KarmaÅŸÄ±k async iÅŸlem baÅŸlatÄ±ldÄ±: {data.get('id', 'unknown')}")
    
    # SimÃ¼le edilmiÅŸ network delay
    await asyncio.sleep(0.5)
    
    # Veri iÅŸleme simÃ¼lasyonu
    processor = JSONProcessor()
    processed_data = await processor.process(data)
    
    # Storage iÅŸlemi
    storage = MemoryStorage()
    key = f"processed_{data.get('id', 'unknown')}"
    await storage.save(key, processed_data)
    
    # SonuÃ§
    result = {
        "original": data,
        "processed": processed_data,
        "storage_key": key,
        "timestamp": datetime.now().isoformat()
    }
    
    logger.info(f"KarmaÅŸÄ±k async iÅŸlem tamamlandÄ±: {data.get('id', 'unknown')}")
    return result

@cache_result(max_size=50)
def expensive_calculation(n: int) -> int:
    """PahalÄ± hesaplama (cache'lenmiÅŸ)"""
    logger.info(f"PahalÄ± hesaplama baÅŸlatÄ±ldÄ±: n={n}")
    
    # SimÃ¼le edilmiÅŸ pahalÄ± iÅŸlem
    time.sleep(0.1)
    
    result = sum(i * i for i in range(n))
    logger.info(f"PahalÄ± hesaplama tamamlandÄ±: n={n}, result={result}")
    
    return result

# Threading Functions
def cpu_bound_task(task_id: str, iterations: int) -> Dict[str, Any]:
    """CPU yoÄŸun gÃ¶rev (threading iÃ§in)"""
    logger.info(f"CPU yoÄŸun gÃ¶rev baÅŸlatÄ±ldÄ±: {task_id}")
    
    start_time = time.time()
    result = 0
    
    for i in range(iterations):
        result += i ** 2
        if i % 100000 == 0:
            logger.debug(f"{task_id}: {i}/{iterations} tamamlandÄ±")
    
    execution_time = time.time() - start_time
    
    return {
        "task_id": task_id,
        "result": result,
        "iterations": iterations,
        "execution_time": execution_time,
        "thread_name": threading.current_thread().name
    }

def run_threaded_tasks(num_tasks: int = 4, iterations: int = 1000000):
    """Ã‡oklu thread'de gÃ¶revleri Ã§alÄ±ÅŸtÄ±r"""
    logger.info(f"Threaded gÃ¶revler baÅŸlatÄ±lÄ±yor: {num_tasks} gÃ¶rev")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=num_tasks) as executor:
        # GÃ¶revleri gÃ¶nder
        futures = []
        for i in range(num_tasks):
            future = executor.submit(cpu_bound_task, f"task_{i}", iterations)
            futures.append(future)
        
        # SonuÃ§larÄ± topla
        results = []
        for future in concurrent.futures.as_completed(futures):
            try:
                result = future.result()
                results.append(result)
                logger.info(f"Thread gÃ¶revi tamamlandÄ±: {result['task_id']}")
            except Exception as e:
                logger.error(f"Thread gÃ¶revi baÅŸarÄ±sÄ±z: {e}")
        
        return results

# Design Patterns
class Observer(ABC):
    """Observer pattern - gÃ¶zlemci"""
    
    @abstractmethod
    def update(self, subject: 'Subject', event: str, data: Any):
        pass

class Subject:
    """Observer pattern - gÃ¶zlemlenen"""
    
    def __init__(self):
        self._observers: List[Observer] = []
        self._state: Dict[str, Any] = {}
    
    def attach(self, observer: Observer):
        """GÃ¶zlemci ekle"""
        if observer not in self._observers:
            self._observers.append(observer)
            logger.debug(f"GÃ¶zlemci eklendi: {observer.__class__.__name__}")
    
    def detach(self, observer: Observer):
        """GÃ¶zlemci Ã§Ä±kar"""
        if observer in self._observers:
            self._observers.remove(observer)
            logger.debug(f"GÃ¶zlemci Ã§Ä±karÄ±ldÄ±: {observer.__class__.__name__}")
    
    def notify(self, event: str, data: Any = None):
        """GÃ¶zlemcileri bilgilendir"""
        logger.info(f"Event yayÄ±nlandÄ±: {event}")
        for observer in self._observers:
            try:
                observer.update(self, event, data)
            except Exception as e:
                logger.error(f"GÃ¶zlemci bilgilendirme hatasÄ±: {e}")
    
    def set_state(self, key: str, value: Any):
        """Durum gÃ¼ncelle"""
        old_value = self._state.get(key)
        self._state[key] = value
        
        if old_value != value:
            self.notify("state_changed", {"key": key, "old": old_value, "new": value})
    
    def get_state(self, key: str) -> Any:
        """Durum al"""
        return self._state.get(key)

class ConcreteObserver(Observer, LoggingMixin):
    """Somut gÃ¶zlemci"""
    
    def __init__(self, name: str):
        self.name = name
    
    def update(self, subject: Subject, event: str, data: Any):
        self.log_info(f"Event alÄ±ndÄ±: {event} - Data: {data}")

# Factory Pattern
class ProcessorFactory:
    """Ä°ÅŸleyici factory'si"""
    
    _processors = {
        "json": JSONProcessor,
        # DiÄŸer iÅŸleyiciler buraya eklenebilir
    }
    
    @classmethod
    def create_processor(cls, processor_type: str) -> DataProcessor:
        """Ä°ÅŸleyici oluÅŸtur"""
        processor_class = cls._processors.get(processor_type.lower())
        if not processor_class:
            raise ValueError(f"Bilinmeyen iÅŸleyici tipi: {processor_type}")
        
        return processor_class()
    
    @classmethod
    def register_processor(cls, processor_type: str, processor_class: type):
        """Yeni iÅŸleyici tipi kaydet"""
        cls._processors[processor_type.lower()] = processor_class

# Test Functions
async def run_comprehensive_test():
    """KapsamlÄ± test fonksiyonu"""
    logger.info("ğŸš€ KapsamlÄ± test baÅŸlatÄ±lÄ±yor...")
    
    try:
        # 1. TaskManager testi
        logger.info("ğŸ“‹ TaskManager testi...")
        task_manager = TaskManager()
        await task_manager.start()
        
        # GÃ¶revler gÃ¶nder
        task_ids = []
        for i in range(10):
            test_data = {"id": i, "data": f"test_data_{i}"}
            task_id = await task_manager.submit_task(complex_async_operation, test_data)
            task_ids.append(task_id)
        
        # SonuÃ§larÄ± bekle
        await asyncio.sleep(3)
        
        # SonuÃ§larÄ± kontrol et
        completed = 0
        for task_id in task_ids:
            result = task_manager.get_task_result(task_id)
            if result and result.status == ProcessStatus.COMPLETED:
                completed += 1
        
        logger.info(f"TaskManager test sonucu: {completed}/{len(task_ids)} gÃ¶rev tamamlandÄ±")
        
        await task_manager.stop()
        
        # 2. Generator testi
        logger.info("ğŸ“‹ Generator testi...")
        fib_numbers = list(fibonacci_generator(10))
        prime_numbers = list(prime_generator(50))
        logger.info(f"Fibonacci: {fib_numbers}")
        logger.info(f"Asal sayÄ±lar: {prime_numbers}")
        
        # 3. Cache testi
        logger.info("ğŸ“‹ Cache testi...")
        for i in range(5):
            result = expensive_calculation(1000)  # Ä°lk Ã§aÄŸrÄ± cache'e alÄ±nÄ±r
            result = expensive_calculation(1000)  # Ä°kinci Ã§aÄŸrÄ± cache'den gelir
        
        # 4. Observer pattern testi
        logger.info("ğŸ“‹ Observer pattern testi...")
        subject = Subject()
        observer1 = ConcreteObserver("Observer1")
        observer2 = ConcreteObserver("Observer2")
        
        subject.attach(observer1)
        subject.attach(observer2)
        
        subject.set_state("test_key", "test_value")
        subject.set_state("another_key", 42)
        
        # 5. Repository testi
        logger.info("ğŸ“‹ Repository testi...")
        user_repo = Repository[str](str)
        user_repo.add("user1", "Alice")
        user_repo.add("user2", "Bob")
        
        logger.info(f"Repository count: {user_repo.count()}")
        logger.info(f"User1: {user_repo.get('user1')}")
        
        # 6. Context manager testi
        logger.info("ğŸ“‹ Context manager testi...")
        with ResourceManager("test_resource") as resource:
            logger.info(f"Resource kullanÄ±lÄ±yor: {resource}")
        
        # 7. Threading testi
        logger.info("ğŸ“‹ Threading testi...")
        thread_results = run_threaded_tasks(num_tasks=3, iterations=500000)
        logger.info(f"Thread test sonucu: {len(thread_results)} gÃ¶rev tamamlandÄ±")
        
        logger.info("âœ… KapsamlÄ± test baÅŸarÄ±yla tamamlandÄ±!")
        
    except Exception as e:
        logger.error(f"âŒ Test hatasÄ±: {e}")
        raise

# Ana fonksiyon
def main():
    """Ana fonksiyon"""
    print("ğŸ GeliÅŸmiÅŸ Python Test Sistemi")
    print("=" * 50)
    
    # Async test'i Ã§alÄ±ÅŸtÄ±r
    asyncio.run(run_comprehensive_test())
    
    print("\nğŸ‰ Test tamamlandÄ±! Log dosyasÄ±nÄ± kontrol edin: advanced_test.log")

if __name__ == "__main__":
    main()
